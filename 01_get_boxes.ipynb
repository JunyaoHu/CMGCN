{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step5.1: get_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行它获得boxes裁剪区块数据，为生成文件夹做准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, set up Python, `numpy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from skimage import transform\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# 防止挂掉\n",
    "os.environ['GLOG_minloglevel'] = '3' \n",
    "# 忽略caffe打印的结构信息！要写在import caffe之前！因为在导入caffe时caffe会加载GLOG！\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (12, 9)        # small images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/hujunyao/ACL22-sarcasm-code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/hujunyao/ACL22-sarcasm-code/bottom-up-attention\n"
     ]
    }
   ],
   "source": [
    "# Change dir to caffe root or prototxt database paths won't work wrong\n",
    "import os\n",
    "os.chdir('/root/hujunyao/ACL22-sarcasm-code/bottom-up-attention')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "sys.path.insert(0, './caffe/python/')\n",
    "sys.path.insert(0, './lib/')\n",
    "sys.path.insert(0, './tools/')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/genome/1600-400-20'\n",
    "\n",
    "# Load classes\n",
    "classes = ['__background__']\n",
    "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        classes.append(object.split(',')[0].lower().strip())\n",
    "\n",
    "# Load attributes\n",
    "attributes = ['__no_attribute__']\n",
    "with open(os.path.join(data_path, 'attributes_vocab.txt')) as f:\n",
    "    for att in f.readlines():\n",
    "        attributes.append(att.split(',')[0].lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check object extraction\n",
    "from fast_rcnn.config import cfg, cfg_from_file\n",
    "from fast_rcnn.test import im_detect,_get_blobs\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "import cv2\n",
    "\n",
    "# GPU_ID = 0   # if we have multiple GPUs, pick one \n",
    "caffe.set_device(0)  \n",
    "caffe.set_mode_gpu()\n",
    "net = None\n",
    "cfg_from_file('experiments/cfgs/faster_rcnn_end2end_resnet.yml')\n",
    "\n",
    "weights = './data/resnet101_faster_rcnn_final.caffemodel'\n",
    "prototxt = 'models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "net = caffe.Net(prototxt, weights, caffe.TEST)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "imgs = os.listdir(\"../data/dataset_image\")\n",
    "imgs.sort()\n",
    "imgs[:10]\n",
    "print(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 3951/24635 [45:47<4:01:36,  1.43it/s]"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "dic = {}\n",
    "# imgs = imgs[:1000]\n",
    "for idx in tqdm(range(len(imgs))):\n",
    "    img = imgs[idx]\n",
    "    im_file = \"../data/dataset_image/\" + img\n",
    "    conf_thresh=0.4\n",
    "    min_boxes=10\n",
    "    max_boxes=20\n",
    "\n",
    "    im = cv2.imread(im_file)\n",
    "    \n",
    "    b,g,r = cv2.split(im)#分别提取B、G、R通道\n",
    "    im = cv2.merge([r,g,b])\n",
    "    scores, boxes, attr_scores, rel_scores = im_detect(net, im)\n",
    "\n",
    "    # Keep the original boxes, don't worry about the regression bbox outputs\n",
    "    rois = net.blobs['rois'].data.copy()\n",
    "    # unscale back to raw image space\n",
    "    blobs, im_scales = _get_blobs(im, None)\n",
    "\n",
    "    cls_boxes = rois[:, 1:5] / im_scales[0]\n",
    "    cls_prob = net.blobs['cls_prob'].data\n",
    "    attr_prob = net.blobs['attr_prob'].data\n",
    "    pool5 = net.blobs['pool5_flat'].data\n",
    "\n",
    "    # Keep only the best detections\n",
    "    max_conf = np.zeros((rois.shape[0]))\n",
    "    for cls_ind in range(1,cls_prob.shape[1]):\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = np.array(nms(dets, cfg.TEST.NMS))\n",
    "        max_conf[keep] = np.where(cls_scores[keep] > max_conf[keep], cls_scores[keep], max_conf[keep])\n",
    "\n",
    "    keep_boxes = np.where(max_conf >= conf_thresh)[0]\n",
    "    if len(keep_boxes) < min_boxes:\n",
    "        keep_boxes = np.argsort(max_conf)[::-1][:min_boxes]\n",
    "    elif len(keep_boxes) > max_boxes:\n",
    "        keep_boxes = np.argsort(max_conf)[::-1][:max_boxes]\n",
    "    ############################\n",
    "\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    boxes = cls_boxes[keep_boxes]\n",
    "    objects = np.argmax(cls_prob[keep_boxes][:,1:], axis=1)\n",
    "    attr_thresh = 0.1\n",
    "    attr = np.argmax(attr_prob[keep_boxes][:,1:], axis=1)\n",
    "    attr_conf = np.max(attr_prob[keep_boxes][:,1:], axis=1)\n",
    "    \n",
    "    dic[img] = list()\n",
    "    \n",
    "    for i in range(len(keep_boxes)):\n",
    "        bbox = boxes[i]\n",
    "        if bbox[0] == 0:\n",
    "            bbox[0] = 1\n",
    "        if bbox[1] == 0:\n",
    "            bbox[1] = 1\n",
    "        cls = classes[objects[i]+1]\n",
    "        if attr_conf[i] > attr_thresh:\n",
    "            # 小小吐槽，这里应该把\" \"改成\"_\"!,不然后面坑死，不过在5.2已经进行了补救，时间不够了,就不重新生成box了！！！！\n",
    "            cls = attributes[attr[i]+1] + \"_\" + cls  \n",
    "            \n",
    "        dic[img].append([bbox,cls])\n",
    "pk.dump(dic,open(\"boxes.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `boxes.pkl`的保存格式\n",
    "\n",
    "对于位置列表：`（左上x,左上y,右下x,右下y)`\n",
    "\n",
    "```\n",
    "os.chdir('/root/hujunyao/ACL22-sarcasm-code/bottom-up-attention'){'893019140839145472.jpg': [\n",
    "  [array([3.3292169e+02, 1.0000000e+00, 1.1991466e+03, 3.4800439e+02],dtype=float32),'gray bridge'],\n",
    "  [array([ 248.29492,  175.57552, 1074.2344 ,  894.50665], dtype=float32),'gray sky'],\n",
    "  [array([ 107.84516,  679.2003 , 1198.2689 ,  894.50665], dtype=float32),'green trees'],\n",
    "  [array([1060.3639 ,  633.52344, 1199.1466 ,  894.50665], dtype=float32),'green tree'],\n",
    "  ...\n",
    "  ],\n",
    " '818606588231553024.jpg': [],...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
